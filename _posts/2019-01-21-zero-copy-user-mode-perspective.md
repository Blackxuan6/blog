---
layout: post
title: 零拷贝 - 用户态分析
---

现在几乎所有人都听过 Linux 下的零拷贝技术，但我经常遇到对这个问题不能深入理解的人。所以我写了这篇文章，来深入研究这些问题。本文通过用户态程序的角度来看零拷贝，因此我有意忽略了内核级别的实现。

# 什么是 “零拷贝” ？

为了更好的理解这个问题，我们首先需要了解问题本身。来看一个网络服务的简单运行过程，在这个过程中将磁盘的文件读取到缓冲区，然后通过网络发送给客户端。下面是示例代码：

```c
read(file, tmp_buf, len); 
write(socket, tmp_buf, len);
```

这个例子看起来非常简单，你可能会认为只有两次系统调用不会产生太多的系统开销。实际上并非如此，在这两次调用之后，数据至少被复制了 4 次，同时还执行了很多次 *用户态/内核态* 的上下文切换。（实际上这个过程是非常复杂的，为了解释我尽可能保持简单）为了更好的理解这个过程，请查看下图中的上下文切换，图片上部分展示上下文切换过程，下部分展示复制操作。

![两次系统调用]({{ "/public/images/2019/01/sys_call_copy.jpg" | prepend: site.cdnurl }} "两次系统调用")

1. 程序调用 `read` 产生一次用户态到内核态的上下文切换。DMA 模块从磁盘读取文件内容，将其复制到内核空间的缓冲区，完成第 1 次复制。
2. 数据从内核缓冲区复制到用户空间缓冲区，之后系统调用 `read` 返回，这回导致从内核空间到用户空间的上下文切换。这个时候数据存储在用户空间的 `tmp_buf` 缓冲区内，可以后续的操作了。
3. 程序调用 `write` 产生一次用户态到内核态的上下文切换。数据从用户空间缓冲区被复制到内核空间缓冲区，完成第 3 次复制。但是这次数据存储在一个和 `socket` 相关的缓冲区中，而不是第一步的缓冲区。
4. `write` 调用返回，产生第 4 个上下文切换。第 4 次复制在 DMA 模块将数据从内核空间缓冲区传递至协议引擎的时候发生，这与我们的代码的执行是独立且异步发生的。你可能会疑惑：“为何要说是独立、异步？难道不是在 `write` 系统调用返回前数据已经被传送了？write 系统调用的返回，并不意味着传输成功——它甚至无法保证传输的开始。调用的返回，只是表明以太网驱动程序在其传输队列中有空位，并已经接受我们的数据用于传输。可能有众多的数据排在我们的数据之前。除非驱动程序或硬件采用优先级队列的方法，各组数据是依照FIFO的次序被传输的(上图中叉状的 DMA copy 表明这最后一次复制可以被延后)。

# mmap

如你所见，上面的数据复制非常多，我们可以减少一些重复复制来减少开销，提升性能。作为一名驱动程序开发人员，我的工作围绕着拥有先进特性的硬件展开。某些硬件支持完全绕开内存，将数据直接传送给其他设备。这个特性消除了系统内存中的数据副本，因此是一种很好的选择，但并不是所有的硬件都支持。此外，来自于硬盘的数据必须重新打包(地址连续)才能用于网络传输，这也引入了某些复杂性。为了减少开销，我们可以从消除内核缓冲区与用户缓冲区之间的复制开始。

减少数据复制的一种方法是将 `read` 调用改为 `mmap`。例如：

```c
tmp_buf = mmap(file, len); 
write(socket, tmp_buf, len);
```

为了方便你理解，请参考下图的过程。

![mmap调用]({{ "/public/images/2019/01/sys_mmap.jpg" | prepend: site.cdnurl }} "mmap 调用")

1. `mmap` 调用导致文件内容通过 DMA 模块复制到内核缓冲区。然后与用户进程共享缓冲区，这样不会在内核缓冲区和用户空间之间产生任何复制。
2. `write` 调用导致内核将数据从原始内核缓冲区复制到与 `socket` 关联的内核缓冲区中。
3. 第 3 次数据复制发生在 DMA 模块将数据从 `socket` 缓冲区传递给协议引擎时。

通过调用 `mmap` 而不是 `read`，我们已经将内核复制数据操作减半。当传输大量数据时，效果会非常好。然而，这种改进并非没有代价；使用 `mmap + write` 方式存在一些隐藏的陷阱。当内存中做文件映射后调用 `write`，与此同时另一个进程截断这个文件时。此时 `write` 调用的进程会收到一个 `SIGBUS` 中断信号，因为当前进程访问了非法内存地址。这个信号默认情况下会杀死当前进程并生成 `dump` 文件——而这对于网络服务器程序而言不是最期望的操作。有两种方式可用于解决该问题：

第一种方法是处理收到的 `SIGBUS` 信号，然后在处理程序中简单地调用 `return`。通过这样做，`write` 调用会返回它在被中断之前写入的字节数，并且将全局变量 `errno` 设置为成功。我认为这是一个治标不治本的解决方案。因为收到 `SIGBUS` 信号表示程序发生了严重的错误，我不推荐使用它作为解决方案。

第二种方式应用了文件租借（在Microsoft Windows系统中被称为“机会锁”)。这才是解劝前面问题的正确方式。通过对文件描述符执行租借，可以同内核就某个特定文件达成租约。从内核可以获得读/写租约。当另外一个进程试图将你正在传输的文件截断时，内核会向你的进程发送实时信号——RT_SIGNAL_LEASE。该信号通知你的进程，内核即将终止在该文件上你曾获得的租约。这样，在write调用访问非法内存地址、并被随后接收到的SIGBUS信号杀死之前，write系统调用就被RT_SIGNAL_LEASE信号中断了。write的返回值是在被中断前已写的字节数，全局变量errno设置为成功。下面是一段展示如何从内核获得租约的示例代码。

```c
if (fcntl(fd, F_SETSIG, RT_SIGNAL_LEASE) == -1) {
    perror("kernel lease set signal");
    return -1;
}
/* l_type can be F_RDLCK F_WRLCK */
if (fcntl(fd, F_SETLEASE, l_type)) {
    perror("kernel lease set type");
    return -1;
}
```

在对文件进行映射前，应该先获得租约，并在结束 `write` 操作后结束租约。这是通过在 `fcntl` 调用中指定租约类型为 `F_UNLCK` 来实现的。

# Sendfile

在内核的 2.1 版本中，引入了 `sendfile` 系统调用，目的是简化通过网络和两个本地文件之间的数据传输。`sendfile` 的引入不仅减少了数据复制，还减少了上下文切换。可以这样使用它：

```c
sendfile(socket, file, len);
```

同样的，为了理解起来方便，可以看下图的调用过程。

![sendfile代替读写]({{ "/public/images/2019/01/sys_sendfile.jpg" | prepend: site.cdnurl }} "sendfile 代替读写")

1. `sendfile` 调用会使得文件内容通过 DMA 模块复制到内核缓冲区。然后，内核将数据复制到与 `socket` 关联的内核缓冲区中。
2. 第 3 次复制发生在 DMA 模块将数据从内核 `socket` 缓冲区传递到协议引擎时。

你可能想问当我们使用 `sendfile` 调用传输文件时有另一个进程截断会发生什么？如果我们没有注册任何信号处理程序，`sendfile` 调用只会返回它在被中断之前传输的字节数，并且全局变量 `errno` 被设置为成功。

但是，如果我们在调用 `sendfile` 之前从内核获得了文件租约，那么行为和返回状态完全相同。我们会在`sendfile` 调用返回之前收到一个 `RT_SIGNAL_LEASE` 信号。

到目前为止，我们已经能够避免让内核产生多次复制，但我们还有一次复制。这可以避免吗？当然，在硬件的帮助下。为了避免内核完成的所有数据复制，我们需要一个支持收集操作的网络接口。这仅仅意味着等待传输的数据不需要在内存中；它可以分散在各种存储位置。在内核 2.4 版本中，修改了 `socket` 缓冲区描述符以适应这些要求 - 在 Linux 下称为零拷贝。这种方法不仅减少了多个上下文切换，还避免了处理器完成的数据复制。对于用户级应用程序，没有任何更改，因此代码仍然如下所示：

```c
sendfile(socket, file, len);
```

![sendfile代替读写]({{ "/public/images/2019/01/sys_call_sendfile.jpg" | prepend: site.cdnurl }} "sendfile 代替读写")